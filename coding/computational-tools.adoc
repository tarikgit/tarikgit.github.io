= Computational Tools

:stem: latexmath
:eqnums:

You can use the following websites to run your (R, julia, Rust) code online, without having to install anything:

* link:https://rextester.com/l/r_online_compiler[Compile R codes online]
* link:https://www.tutorialspoint.com/execute_julia_online.php[Execute Julia code online]
* link:https://www.tutorialspoint.com/compile_rust_online.php[Execute Rust code online]


== Slice sampler

This part is taken from link:https://www.springer.com/gp/book/9780387212395[Robert and Casella (2004)].

At iteration _t_, simulate:

\begin{eqnarray}
 u^{(t+1)} &\sim& U_{[0,f(x^{(t)}]} \nonumber \\
 x^{(t+1)} &\sim& U_{A^{(t+1)}} \nonumber 
\end{eqnarray}
with $A^{(t+1)} = \{ x: f(x) \geq u^{(t+1)} \}$


=== Example 1

In this example, the _slice sampler_ will be used to simulate from the density:
\[
f(x)=\frac{1}{2}\exp( -\sqrt{x} )
\]

At iteration _t_, simulate: 
\begin{eqnarray}
 u^{(t+1)} &\sim& U_{[0,\frac{1}{2}\exp( -\sqrt{x} )]} \nonumber \\
 x^{(t+1)} &\sim& U_{[0,(-\log(2u))^2]} \nonumber 
\end{eqnarray}

Using *R*

[source,R]
----
# Sample from 0.5*exp(-sqrt(x))
# using the slice sampler

f <- function(y)exp(-sqrt(y))/2;

nsim <- 50000;

x <- array(0,dim=c(nsim,1));
x[1] <- -log(runif(1));

for (i in 2:nsim)  {
     w <- runif(1,min=0,max=f(x[i-1]));
     x[i] <- runif(1,min=0,max=(-log(2*w))^2);
}

hist(x,main="Slice sample",xlim=c(0,60),ylim=c(0,.25),freq=F,col="green",breaks=250)

par(new=T)

plot(function(y)f(y), 0, 70, xlim=c(0,60),ylim=c(0,.25),xlab="",ylab="",xaxt="n",yaxt="n",lwd=3)

----


Using *julia*

[source,julia]
----

using Random, Distributions

# Setting the seed
Random.seed!(123) 

function f(y)
    exp( -sqrt(y) ) / 2
end

nsim = 50000

x = rand(Uniform(0.0,1.0),nsim,1)

x[1] = -log.( rand(Uniform(0.0,1.0)) )

for i in 2:nsim
    w = rand(Uniform(0.0,f(x[i-1])))
    x[i] = rand(Uniform(0.0,(-log.(2*w))^2))
end

# Histogram of density
using Plots; pyplot()
Plots.PyPlotBackend()
histogram(x)

----


=== Example 2
Now we consider a truncated normal distribution $\mathcal{N}$(3,1), which is restricted to the interval [0,1]. 

In this example, the _slice sampler_ will be used to simulate from the density:
[stem]
++++
f(x) \varpropto f_1(x) = \exp\big( -(x+3)^2/2 \big) \mathbb{1}_{[0,1]}{(x)}
++++



At iteration _t_, simulate: 
\begin{eqnarray}
 u^{(t+1)} &\sim& \exp\big( -(x+3)^2/2 \big) U_{[0,1]} \nonumber \\
 x^{(t+1)} &\sim& U_{[0,(-3+\sqrt{-2\log(u)})]} \nonumber
\end{eqnarray}


[source,R]
----

# Sample from a N(-3,1) truncated to [0,1]
# using the slice sampler

nsim = 1000

obs <- matrix(0,nsim,2)
obs[1,1] = .25
obs[1,2] = 0.5*exp(-0.5*(obs[1,1]+3)^2)

for (i in 2:nsim){
 obs[i,2] = exp(-0.5*(obs[i-1,1]+3)^2)*runif(1)
 obs[i,1] = runif(1)*min(1,-3+sqrt(-2*log(obs[i,2])))
 }
    
hist(obs,main="Slice sample",freq=F,col="green", breaks=25)

----



== Monte Carlo Integration

Consider the function,
\begin{eqnarray}
  h(x) = [ \cos(50x) + \sin(20x) ]^2 \nonumber
\end{eqnarray}

The integral,
\begin{eqnarray}
  \int^1_0 h(x) dx \nonumber
\end{eqnarray}
can be calculated by generating
\[
   U_1, U_2, \ldots, U_n  \sim  iid \quad U(0,1) 
\]
random variables, and approximate $\int h(x) dx$ with
\[
   \sum^n_{i=1} h(U_i)/n
\]

Using *R*

[source,R]
----

nsim <- 10000;
u <- runif(nsim);
den <- 1:(nsim)

# The function to be integrated
mci.ex <- function(x){(cos(50*x)+sin(20*x))^2}
par(mfrow=c(1,3))
plot(function(x)mci.ex(x), xlim=c(0,1),ylim=c(0,4),xlab="Function",ylab="")
    
# The Monte Carlo sum
## Generated Values of Function
hint <- mci.ex(u)
## Mean
hplot <- cumsum(hint)/den
## Standard Errors
stdh <- sqrt( cumsum(hint^2)/den - (hplot)^2)
upper <- hplot+stdh/sqrt(den)
lower <- hplot-stdh/sqrt(den)

----


== Simulated Annealing

Given a _temperature_ parameter $T>0$, a sample $\theta^T_1, \theta^T_2, \ldots$ is generated from the distribution
\[
 \pi(\theta) \varpropto \exp( h(\theta)/T ) 
\]


=== Example 3

We are searching for the maximum of the following function
\[
  h(x) = [ \cos(50x) + \sin(20x) ]^2
\]

At iteration _t_ the algorithm is at $( x^{(t)},h^{(t)} )$:

. Simulate $u \sim U(a_t, b_t)$ where $a_t = \max( x^{(t)}-r,0 )$ and $b_t = \min( x^{(t)}+r,1 )$
. Accept $x^{(t+1)}=u$ with probability
\[
  \rho^{(t)} = \min \big\{  \exp \big(  \frac{h(u)-h(x^{(t)})}{T_t} \big), 1  \big\}
\]
take $x^{(t+1)}=x^{(t)}$ otherwise.
. Update $T_t$ to $T_{t+1}$

[source,R]
----

par(mfrow=c(1,2))

# The function to be optimized
mci <- function(x){(cos(50*x)+sin(20*x))^2}

# The Monte Carlo maximum
nsim <- 2500
u <- runif(nsim)

# Simulated annealing
xval <- array(0,c(nsim,1));
r <- .5
for(i in 2:nsim){
    test <- runif(1, min=max(xval[i-1]-r,0),max=min(xval[i-1]+r,1));
    delta <- mci(test) - mci(xval[i-1]);
    rho <- min(exp(delta*log(i)/1),1);
    xval[i] <- test*(u[i]<rho)+xval[i-1]*(u[i]>rho)
}
mci(xval[nsim])

# Plot the trajectory of the optimization path
plot(function(x)mci(x), xlim=c(0,1),ylim=c(0,4),xlab="Function",ylab="")
plot(xval,mci(xval),type="l",lwd=2)
 

----

