= Computational Tools

:stem: latexmath
:eqnums:

You can use the following websites to run your (R, julia, Rust) code online, without having to install anything:

* link:https://rextester.com/l/r_online_compiler[Execute R codes online]
* link:https://repl.it/languages/julia[Execute Julia code online]
* link:https://www.tutorialspoint.com/compile_rust_online.php[Compile Rust code online]
* link:https://rextester.com/l/octave_online_compiler[Execute Octave code online]

== Slice sampler

This part is taken from link:https://www.springer.com/gp/book/9780387212395[Robert and Casella (2004)].

At iteration _t_, simulate:

\begin{eqnarray}
 u^{(t+1)} &\sim& U_{[0,f(x^{(t)}]} \nonumber \\
 x^{(t+1)} &\sim& U_{A^{(t+1)}} \nonumber 
\end{eqnarray}
with $A^{(t+1)} = \{ x: f(x) \geq u^{(t+1)} \}$


=== Example 1

In this example, the _slice sampler_ will be used to simulate from the density:
\[
f(x)=\frac{1}{2}\exp( -\sqrt{x} )
\]

At iteration _t_, simulate: 
\begin{eqnarray}
 u^{(t+1)} &\sim& U_{[0,\frac{1}{2}\exp( -\sqrt{x} )]} \nonumber \\
 x^{(t+1)} &\sim& U_{[0,(-\log(2u))^2]} \nonumber 
\end{eqnarray}

Using *R*

[source,R]
----
# Sample from 0.5*exp(-sqrt(x))
# using the slice sampler

f <- function(y)exp(-sqrt(y))/2;

nsim <- 50000;

x <- array(0,dim=c(nsim,1));
x[1] <- -log(runif(1));

for (i in 2:nsim)  {
     w <- runif(1,min=0,max=f(x[i-1]));
     x[i] <- runif(1,min=0,max=(-log(2*w))^2);
}

hist(x,main="Slice sample",xlim=c(0,60),ylim=c(0,.25),freq=F,col="green",breaks=250)

par(new=T)

plot(function(y)f(y), 0, 70, xlim=c(0,60),ylim=c(0,.25),xlab="",ylab="",xaxt="n",yaxt="n",lwd=3)

----


Using *julia*

[source,julia]
----

using Random, Distributions

# Setting the seed
Random.seed!(123) 

function f(y)
    exp( -sqrt(y) ) / 2
end

nsim = 50000

x = rand(Uniform(0.0,1.0),nsim,1)

x[1] = -log.( rand(Uniform(0.0,1.0)) )

for i in 2:nsim
    w = rand(Uniform(0.0,f(x[i-1])))
    x[i] = rand(Uniform(0.0,(-log.(2*w))^2))
end

# Histogram of density
using Plots; pyplot()
Plots.PyPlotBackend()
histogram(x)

----


=== Example 2
Now we consider a truncated normal distribution $\mathcal{N}$(3,1), which is restricted to the interval [0,1]. 

In this example, the _slice sampler_ will be used to simulate from the density:
[stem]
++++
f(x) \varpropto f_1(x) = \exp\big( -(x+3)^2/2 \big) \mathbb{1}_{[0,1]}{(x)}
++++



At iteration _t_, simulate: 
\begin{eqnarray}
 u^{(t+1)} &\sim& \exp\big( -(x+3)^2/2 \big) U_{[0,1]} \nonumber \\
 x^{(t+1)} &\sim& U_{[0,(-3+\sqrt{-2\log(u)})]} \nonumber
\end{eqnarray}


[source,R]
----

# Sample from a N(-3,1) truncated to [0,1]
# using the slice sampler

nsim = 1000

obs <- matrix(0,nsim,2)
obs[1,1] = .25
obs[1,2] = 0.5*exp(-0.5*(obs[1,1]+3)^2)

for (i in 2:nsim){
 obs[i,2] = exp(-0.5*(obs[i-1,1]+3)^2)*runif(1)
 obs[i,1] = runif(1)*min(1,-3+sqrt(-2*log(obs[i,2])))
 }
    
hist(obs,main="Slice sample",freq=F,col="green", breaks=25)

----



== Monte Carlo Integration

Consider the function,
\begin{eqnarray}
  h(x) = [ \cos(50x) + \sin(20x) ]^2 \nonumber
\end{eqnarray}

The integral,
\begin{eqnarray}
  \int^1_0 h(x) dx \nonumber
\end{eqnarray}
can be calculated by generating
\[
   U_1, U_2, \ldots, U_n  \sim  iid \quad U(0,1) 
\]
random variables, and approximate $\int h(x) dx$ with
\[
   \sum^n_{i=1} h(U_i)/n
\]

Using *R*

[source,R]
----

nsim <- 10000;
u <- runif(nsim);
den <- 1:(nsim)

# The function to be integrated
mci.ex <- function(x){(cos(50*x)+sin(20*x))^2}
par(mfrow=c(1,3))
plot(function(x)mci.ex(x), xlim=c(0,1),ylim=c(0,4),xlab="Function",ylab="")
    
# The Monte Carlo sum
## Generated Values of Function
hint <- mci.ex(u)
## Mean
hplot <- cumsum(hint)/den
## Standard Errors
stdh <- sqrt( cumsum(hint^2)/den - (hplot)^2)
upper <- hplot+stdh/sqrt(den)
lower <- hplot-stdh/sqrt(den)

----


== Simulated Annealing

Given a _temperature_ parameter $T>0$, a sample $\theta^T_1, \theta^T_2, \ldots$ is generated from the distribution
\[
 \pi(\theta) \varpropto \exp( h(\theta)/T ) 
\]


=== Example 3

We are searching for the maximum of the following function
\[
  h(x) = [ \cos(50x) + \sin(20x) ]^2
\]
Note: Variable 

At iteration _t_ the algorithm is at $( x^{(t)},h^{(t)} )$:

. Simulate $u \sim U(a_t, b_t)$ where $a_t = \max( x^{(t)}-r,0 )$ and $b_t = \min( x^{(t)}+r,1 )$
. Accept $x^{(t+1)}=u$ with probability
\[
  \rho^{(t)} = \min \big\{  \exp \big(  \frac{h(u)-h(x^{(t)})}{T_t} \big), 1  \big\}
\]
take $x^{(t+1)}=x^{(t)}$ otherwise.
. Update $T_t$ to $T_{t+1}$

[source,R]
----

par(mfrow=c(1,2))

# The function to be optimized
mci <- function(x){(cos(50*x)+sin(20*x))^2}

# The Monte Carlo maximum
nsim <- 2500
u <- runif(nsim)

# Simulated annealing
xval <- array(0,c(nsim,1));
r <- .5
for(i in 2:nsim){
    test <- runif(1, min=max(xval[i-1]-r,0),max=min(xval[i-1]+r,1));
    delta <- mci(test) - mci(xval[i-1]);
    rho <- min(exp(delta*log(i)/1),1);
    xval[i] <- test*(u[i]<rho)+xval[i-1]*(u[i]>rho)
}
mci(xval[nsim])

# Plot the trajectory of the optimization path
plot(function(x)mci(x), xlim=c(0,1),ylim=c(0,4),xlab="Function",ylab="")
plot(xval,mci(xval),type="l",lwd=2)
 

----


== Metropolis-Hastings Algorithm

Let $q(\theta, \vartheta)$ be a _proposal density_ or a _candidate-generating density_ (link:http://www2.stat.duke.edu/~scs/Courses/Stat376/Papers/Basic/ChibGreenberg1995.pdf[Chib and Greenberg, 1995]) such that
\[
 \int q(\theta, \vartheta) d\vartheta = 1
\]
Also let $U(O, 1)$ denote the uniform distribution over $(0, 1)$. Then, a general version of the Metropolis- Hastings algorithm for sampling from the posterior distribution $\pi(\theta,D)$ can be described as follows:

. Choose an arbitrary starting point $\theta_0$ and set $i=0$.
. Generate a candidate point $\theta^*$ from $q(\theta_i,\cdot)$ and $u$ from $U(0,1)$.
. Set $\theta_{i+1}=\theta^*$ if $u \leq a(\theta_i, \theta^*)$ and $\theta_{i+1}=\theta_i$ otherwise, where the acceptance probability is given by
\[
 a(\theta,\vartheta) = \min\big\{ 
                        \frac{ \pi(\vartheta|D)q(\vartheta, \theta) }{ \pi(\theta|D)q(\theta, \vartheta) },
                        1
                        \big\}
\]
. Set $i=i+1$, and go to Step 2.

=== Example 4

Let us consider the following simple linear model:
\[
 y_t = \alpha x_t + \beta + \epsilon_t
\]
where $\epsilon \sim N(0, \sigma^2)$.




_Source_: R code taken from link:https://theoreticalecology.wordpress.com/2010/09/17/metropolis-hastings-mcmc-in-r/[A simple Metropolis-Hastings MCMC in R]

[source,R]
----

### Creating test data
trueA <- 5
trueB <- 0
trueSd <- 10
sampleSize <- 31
 
# create independent x-values 
x <- (-(sampleSize-1)/2):((sampleSize-1)/2)
# create dependent values according to ax + b + N(0,sd)
y <-  trueA * x + trueB + rnorm(n=sampleSize,mean=0,sd=trueSd)
 
plot(x,y, main="Test Data")


### Deriving the likelihood
likelihood <- function(param){
    a = param[1]
    b = param[2]
    sd = param[3]
     
    pred = a*x + b
    singlelikelihoods = dnorm(y, mean = pred, sd = sd, log = T)
    sumll = sum(singlelikelihoods)
    return(sumll)   
}
 
# Example: plot the likelihood profile of the slope a
slopevalues <- function(x){return(likelihood(c(x, trueB, trueSd)))}
slopelikelihoods <- lapply(seq(3, 7, by=.05), slopevalues )
plot (seq(3, 7, by=.05), slopelikelihoods , type="l", xlab = "values of slope parameter a", ylab = "Log likelihood")


### Defining the prior
# Prior distribution
prior <- function(param){
    a = param[1]
    b = param[2]
    sd = param[3]
    aprior = dunif(a, min=0, max=10, log = T)
    bprior = dnorm(b, sd = 5, log = T)
    sdprior = dunif(sd, min=0, max=30, log = T)
    return(aprior+bprior+sdprior)
}

### Defining the posterior
posterior <- function(param){
   return (likelihood(param) + prior(param))
}



######## Metropolis algorithm ################
 
proposalfunction <- function(param){
    return(rnorm(3,mean = param, sd= c(0.1,0.5,0.3)))
}
 
run_metropolis_MCMC <- function(startvalue, iterations){
    chain = array(dim = c(iterations+1,3))
    chain[1,] = startvalue
    for (i in 1:iterations){
        proposal = proposalfunction(chain[i,])
         
        probab = exp(posterior(proposal) - posterior(chain[i,]))
        if (runif(1) < probab){
            chain[i+1,] = proposal
        }else{
            chain[i+1,] = chain[i,]
        }
    }
    return(chain)
}
 
startvalue = c(4,0,10)
chain = run_metropolis_MCMC(startvalue, 10000)
 
burnIn = 5000
acceptance = 1-mean(duplicated(chain[-(1:burnIn),]))


### Summary: #######################
 
par(mfrow = c(2,3))
hist(chain[-(1:burnIn),1],nclass=30, , main="Posterior of a", xlab="True value = red line" )
abline(v = mean(chain[-(1:burnIn),1]))
abline(v = trueA, col="red" )
hist(chain[-(1:burnIn),2],nclass=30, main="Posterior of b", xlab="True value = red line")
abline(v = mean(chain[-(1:burnIn),2]))
abline(v = trueB, col="red" )
hist(chain[-(1:burnIn),3],nclass=30, main="Posterior of sd", xlab="True value = red line")
abline(v = mean(chain[-(1:burnIn),3]) )
abline(v = trueSd, col="red" )
plot(chain[-(1:burnIn),1], type = "l", xlab="True value = red line" , main = "Chain values of a", )
abline(h = trueA, col="red" )
plot(chain[-(1:burnIn),2], type = "l", xlab="True value = red line" , main = "Chain values of b", )
abline(h = trueB, col="red" )
plot(chain[-(1:burnIn),3], type = "l", xlab="True value = red line" , main = "Chain values of sd", )
abline(h = trueSd, col="red" )
 
# for comparison:
summary(lm(y~x))

----


The following table gives the equivalence of the variables used in the pseudo-code to the variables used in the R code:

[%header,cols=2*] 
|===
|Theory
|Code

|$\theta$
|chain[,]

|$u$
|runif(1)

|$a(\theta_i, \theta^*)$
|probab

|$\min \big\{  \frac{\pi(\vartheta\|D)q(\vartheta,\theta)}{\pi(\theta\|D)q(\theta,\vartheta)}  \big\}$
|exp( posterior(proposal) - posterior(chain[i,]) )

|$\theta_0$
|c(4,0,10)

|$\theta^*$
|proposal
|===



== Dynamic programming and value function iteration

Consider the following dynamic optimization problem:
\[
 \max_{ \{ x_{t+1} \}^{\infty}_{t=0} } \Sigma^{\infty}_{t=0}\beta^t F(x_t, x_{t+1}) \\
 \mbox{s.t.} \quad  x_{t+1} \in \Gamma(x_t)
\]

The _functional equation_ of the previous problem is given by:
\[
 v(x) = \max_{y\in \Gamma(x)} \big[ F(x,y) + \beta v(y) \big]
\]

Introducing the _optimal policy function_ $g$, we can rewrite the previous expression:
\[
 v(x) = F\big[ x, g(x) + \beta v[g(x)] \big]
\]

The _first-order condition_ and the _envelope condition_ is defined as:
\begin{eqnarray}
 0 &=& F_y[ x, g(x) ] + \beta v'[g(x)] \nonumber \\
 v'(x) &=& F_x[ x, g(x) ] \nonumber
\end{eqnarray}

The _Euler equation_ and the _transversality condition_ is given by:
\begin{eqnarray}
 0 &=& F_y(x_t, x_{t+1}) + \beta F_x (x_{t+1}, x_{t+2}), \quad t=0,1,2, \ldots \nonumber \\
 0 &=& \lim_{t\rightarrow \infty} \beta^t F_x(x_t, x_{t+1}) \cdot x_t \nonumber
\end{eqnarray}

=== Example 5

*The Model*

Let us consider the following _functional equation_:
\[
 v(k) = \max_{k'\geq 0} \big\{  U\big( f(k)-k' \big) + \beta v(k') \big\}
\]
with $k'+c\leq f(k)$, $c\geq 0$ and $y=f(k)$

The model is specified as follows:
\[
  f(k) = k^{\alpha} \\
  U(c) = \log(c)
\]
and it is parameterized as follows
\begin{eqnarray}
 \alpha &=& 0.3 \nonumber \\
 \beta &=& 0.9 \nonumber
\end{eqnarray}

*First Order and Envelope Conditions*

\begin{eqnarray}
 v(k) &=& \max_{c,k'} \big\{ U(c) +  \beta v(k') \big\} \nonumber \\
 && \mbox{s.t.} \quad f(k) - k' - c \geq 0 \quad \quad  [\lambda] \nonumber
\end{eqnarray}



\begin{eqnarray}
 \frac{\partial v(k)}{\partial k'} = 0 \iff \beta \frac{\partial v(k')}{\partial k'} - \lambda = 0 \nonumber
\end{eqnarray}

\begin{eqnarray}
 \boxed{\lambda = \beta \frac{\partial v(k')}{\partial k'} } \nonumber
\end{eqnarray}



\begin{eqnarray}
 \frac{\partial v(k)}{\partial k} &=& \beta \frac{\partial v(k')}{\partial k'} 
                                        + \lambda \big[ \frac{\partial f(k)}{\partial k} - \frac{k'}{k} \big]
                                        \nonumber \\
                                &=& \underbrace{\big[ \beta \frac{\partial v(k')}{\partial k'} - \lambda \big]}_{=0} \frac{k'}{\partial k} + \lambda \frac{\partial f(k)}{\partial k}
                                \nonumber
\end{eqnarray}
which yields the _envelope condition_
\[
 \boxed{ \frac{\partial v(k')}{\partial k'} = \lambda' \frac{\partial f(k')}{\partial k'} }
\]

By combining the two boxed expressions, we get the _first-order condition_
\[
 \boxed{ \lambda = \lambda' \beta \frac{\partial f(k')}{\partial k'} }
\]
and
\[
 \frac{\partial v(k)}{\partial c} = 0 \iff \frac{\partial U(c)}{\partial c} - \lambda = 0
\]

\[
 \boxed{ \lambda = \frac{\partial U(c)}{\partial c} }
\]

*Steady-state*

By combining the _first-order condition_ with the following expressions
\begin{eqnarray}
 \frac{\partial U(c)}{\partial c} &=& c^{-1} \nonumber \\
 \frac{\partial f(k)}{\partial k} &=& \alpha k^{\alpha-1} \nonumber
\end{eqnarray}
we can find the _steady-state value_ of $k$ 
\[
  k^* = \Bigg( \frac{1}{\alpha\beta} \Bigg)^{\frac{1}{\alpha-1}}
\]

*Numerical Solution*

The _numerical solution algorithm_ (value function iteration) is given by (link:https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1120686[Heer and Maussner, 2008]):

. Choose a grid
 $\mathcal{K} = [ K_1, K_2, \ldots, K_n]$  with  $K_i < K_j$ and $i < j = 1$,$2$,$\ldots$, $n$

. Initialize the value function: $\forall i = 1, \ldots, n$ set
\[
 v_i^0 = \frac{u(f(K^*)-K^*)}{1-\beta}
\]
where $K^*$ denotes the stationary solution to the initial problem
. Compute a new value function and the associated policy function, $\underline{v}^1$ and $\underline{h}^1$ respectively: Put $j^*_0 \equiv 1$. For $i=1,2,\ldots , n$ and $j^*_{i-1}$ find the index $j^*_i$ that maximizes
\[
 u\big( f(K_i)-K_j \big) + \beta v^0_j
\]
in the set of indices $\{ j^*_{i-1}, j^*_{i-1}+1, \ldots, n \}$. Set $h^1_i=j^*_i$ and $v^1_i=u\big( f(K_i)-K_{j^*_i} \big) + \beta v^0_{j^*_i}$
. Check for convergence: If $\parallel \underline{v}^0-\underline{v}^1 \parallel_{\infty} < \epsilon (1-\beta)$, $\epsilon \in \mathbb{R}_{++}$ stop, else replace $\underline{v}^0$ with $\underline{v}^1$ and $\underline{h}^0$ with $\underline{h}^1$ and return to step 3. 

Using *Octave*

[source,Octave]
----

% Deterministic Growth model
% Original code by Joao Ejarque and Russell Cooper
% Tarik OCAKTAN - Paris - May 2009

% State space dimension = 1

% Notation:  
%  pName : structural parameters
%  iName : total number of variables related to the algorithm
%  idxName : indexation used in loops, i.e. idxName = 1,...,iName
%  dName : integer of a specific value of a variable, i.e. dNamess=steady state 
%          of
%							   variable 'Name'
%  vName : vector containing values of variable 'Name' 
%  mName : matrix containing values of a variable 'Name'

clear;clc; 
close all;

% Structural parameters
pAlpha	= .3;
pBeta	= .9;
     
% Algorithm parameters
 iIter = 2000; % maximum number of iterations
 iGridPoints = 300;
 iToler	= 10e-6;  % convergence criterion
% Steady state value
 dKss = ( 1 / (pAlpha*pBeta) )^( 1 / (pAlpha-1) );
% Bounds of state space
 dKmin	= dKss * 0.9;
 dKmax	= dKss * 1.1;
% Construct a grid
 iStep	= (dKmax-dKmin) / (iGridPoints-1);
 vK	= dKmin:iStep:dKmax;
 iGridPoints = size(vK,2); % overwriting iGridPoints in order to take into 
			   % account additional point

vY = vK.^pAlpha;
vIota = ones(iGridPoints,1);

% Budget constraint
mC = vIota*vY - vK'*vIota';

% Eliminate negative or zero consumption values
mCP	= mC > 0;  % Matrix of ones where C>0 and zeros elsewhere
mPC	= 1 - mCP; % Matrix with ones where C<=0. this is a penalty matrix
z	= 10e-5;
mC	= mC.*mCP + z*mPC;

% Initialization
 % Initializing the utility function mU
 mU = log(mC);

 % Initializing the value function vVNew
 mCF = vIota*vY ;
 mVNew = log(mCF);

 % Initializing the value function vVOld
 vVOld = max([ mU + pBeta*mVNew ]);

%%% Main Iteration - BEGIN %%%
for idxIter=1:iIter

 idxIter

 vVNew = max([ mU + pBeta*(vIota*vVOld)' ]);

 iDiff = ( abs(vVOld-vVNew) ) / vVOld;
 if iDiff <= iToler
  vVOld = vVNew; 
  break
 else
  vVOld = vVNew;
 end 

end
%%% Main Iteration - END %%%



%break

% Construct policy function
[maxR,idxR] = max([ mU + pBeta*(vIota*vVOld)' ]);

vKP  = vK(idxR); 
vInv = vKP;

figure(1)
plot(vK,vKP)
figure(2)
plot(vK,vY)
disp(idxIter)


----



=== Example 6

Let us consider the following _two-dimensional deterministic model_:
\begin{eqnarray}
 v(k,n) = \max_{ n',k',c }
    \Bigg\{
     U(c) - G(n) &+& \beta v(k',n')
    \Bigg\}  \nonumber \\
     \mbox{ s.t. } \quad f(k,n)-k'-c-(1-n) &\geq& 0 \quad [\lambda] \nonumber \nonumber \\
     \quad \quad \quad (1-s)n + p(1-n) - n' &\geq& 0 \quad [\mu] \nonumber 
\end{eqnarray}

The first-order conditions describing the dynamics of this system are given by:

\begin{eqnarray}
k^{\theta} n^{1-\theta} - k' - c - 1 + n &=& 0 \nonumber \\
(1-s)n + p(1-n) - n' &=& 0  \nonumber  
\end{eqnarray}

\[
 \beta (c')^{-1} \theta k^{ \theta - 1 } n^{ 1 - \theta } = c^{ -1 }
\]

\[
 \beta \Bigg[ -(n')^{-1} + (c')^{-1} \Bigg( 1+(1-\theta)k^{\theta}n^{-\theta} \Bigg) + \mu'(1-s-p)  \Bigg]  = \mu \nonumber 
\]


Using the previous equations, we can compute the steady state values for the four variables, which is given by:
\[
 k^* = \Bigg[ \frac{1}{\beta\theta\big( \frac{p}{s+p} \big)^{1-\theta}} \Bigg]^{\frac{1}{\theta-1}} \\
 n^* = \frac{p}{s+p} \\
 c^* = (k^*)^{\theta} (n^*)^{1-\theta} - k^* - 1 + n^* \\
 \mu^* = \frac{ \beta\big[ -(n^*)^{-1} + (c^*)^{-1} \big( 1+(1-\theta)(k^*)^{\theta}(n^*)^{-\theta} \big) \big] }{1-\beta(1-s-p)}
\]

The model is parameterized as follows:
[%header,cols=2*] 
|===
|Parameter
|Value

|$\beta$
|0.95

|$\theta$
|0.2

|$s$
|0.3

|$p$
|0.75

|===


Using *Octave*

[source,Octave]
----

clear;clc;
close all;

% Structural parameters
Parameters.pBeta = .95;
Parameters.pTheta = .2;
Parameters.pS = .3;
Parameters.pP = .75;

% Algorithm parameters
 iIter = 2000; % maximum number of iterations
 Grid.nK = 3;
 Grid.nN = 2;
 iToler	= 10e-6;  % convergence criterion
 
% Steady state value
 dKss = ( 1 / (Parameters.pBeta*Parameters.pTheta*(Parameters.pP/(Parameters.pS+Parameters.pP))^(1-Parameters.pTheta)) )^( 1 / (Parameters.pTheta-1) );
 dNss = Parameters.pP/(Parameters.pS+Parameters.pP);
 dCss = (dKss)^(Parameters.pTheta)*(dNss)^(1-Parameters.pTheta)-dKss-1+dNss;
 dMu = ( Parameters.pBeta*( -dNss^(-1)+dCss^(-1)*( 1+(1-Parameters.pTheta)*dKss^Parameters.pTheta * dNss^(-Parameters.pTheta) ) ) )/( 1-Parameters.pBeta*(1-Parameters.pS-Parameters.pP) );
 
% Bounds of state space
 dKmin	= dKss * 0.9;
 dKmax	= dKss * 1.1;
 dNmin = dNss * 0.9;
 dNmax = dNss * 1.1;
 
% Create a grid for K and N
Grid.K = linspace(dKmin, dKmax,Grid.nK)'; 
Grid.N = linspace(dNmin, dNmax,Grid.nN)'; 

% Storage space for consumption
mC = ones( (Grid.nN-1)*Grid.nK , Grid.nK);
mY = ones( Grid.nN, Grid.nK );

for iN=1:Grid.nN
    for iKp=1:Grid.nK
        for iK=1:Grid.nK
            mY( iN, iK ) = Grid.K(iK)^Parameters.pTheta*Grid.N(iN)^(1-Parameters.pTheta);
            mC( (iN-1)*Grid.nK+iKp, iK ) = Grid.K(iK)^Parameters.pTheta*Grid.N(iN)^(1-Parameters.pTheta) - Grid.K(iKp) - 1 + Grid.N(iN);
        end
    end
end

% Eliminate negative or zero consumption
cp = mC > 0;
pc = 1 - cp;
z = 10e-5;
mC = mC.*cp + z*pc;

% Initialize the utility function
mU = log( mC );


% Initializing the value function vVNew
mCF = ones( Grid.nN*Grid.nK, Grid.nN )*mY ;
mVNew = log(mCF);


% Initializing the value function vVOld
vVOld = max([ mU + Parameters.pBeta*mVNew ]);


%%% Main Iteration - BEGIN %%%
for idxIter=1:iIter

 idxIter

 vVNew = max([ mU + Parameters.pBeta*( ones( Grid.nN*Grid.nK, 1 )*vVOld ) ]);

 iDiff =  ( abs(vVOld-vVNew) ) / vVOld ;
 
 
 if abs(iDiff) <= iToler
  vVOld = vVNew;
  break
 else
  vVOld = vVNew;
 end

end
%%% Main Iteration - END %%%

% Construct policy function
[maxR,idxR] = max([ mU + Parameters.pBeta*( vVOld'*ones( 1, Grid.nK ) ) ]');


% INCORRECT

vKP  = Grid.K(idxR);
vInv = vKP;


figure(1)
plot(Grid.K,vKP(1:Grid.nK))

break
figure(2)
plot(Grid.K,mY(1,:))
disp(idxIter)



----